<!DOCTYPE html>
<html lang="en">
<html>
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="../static/styles.css">
        <title>TXTRNZ</title>
    </head>
    <body>
    <header>
        <p>Text-Only Version <a class="full-version-link button" href="https://www.rnz.co.nz/news/world/538722/what-meta-s-move-to-community-moderation-could-mean-for-misinformation">Go to article page</a></p>
    </header>
    <h1><a href="/">TXTRNZ</a></h1>
        <div class="hr-line"></div>
        <h2>What Metaâ€™s move to community moderation could mean for misinformation</h2>
        <p>
Analysis - Meta has announced it will discontinue its third-party fact-checking programmes, but what will that mean?
</p>
        
            <p>By Denitsa Dineva of </p>
        
            <p>
Meta is the parent company of Facebook, Instagram, WhatsApp and other services. 
Photo: Victor Okhrimets / 123RF
</p>
        
            <p>Analysis - Meta, the parent company of Facebook, Instagram, WhatsApp and other services has announced it will discontinue its third-party fact-checking programmes, starting in the US.</p>
        
            <p>Journalists and anti-hate speech activists have criticised the decision as an attempt to curry favour with the incoming US President Donald Trump, but there could be an even more cynical reason.</p>
        
            <p>Meta's strategy could be a calculated move for greater user engagement and income.</p>
        
            <p>This decision marks a significant shift in how the social media giant addresses misinformation on its platforms.</p>
        
            <p>Meta's official rationale for ending its independent fact-checking in favour of crowdsourced contributions centres on promoting free expression.</p>
        
            <p>
Chief executive Mark Zuckerberg said the company seeks to reduce censorship and will concentrate its enforcement efforts on illegal or highly harmful content. 
Photo: Supplied/ YouTube
</p>
        
            <p>Chief executive Mark Zuckerberg said the company seeks to reduce censorship and will concentrate its enforcement efforts on illegal or highly harmful content.</p>
        
            <p>This move aligns with broader discussions among governments, social media companies, civil society groups and the public on balancing freedom of expression and content moderation.</p>
        
            <p>These debates have become urgent, as there is mounting evidence that there are biases in content moderation.</p>
        
            <p>For example, a 2023 University of Cambridge study discusses how biases in content moderation disadvantage the cultural, social, and economic rights of marginalised communities.</p>
        
            <p>The crowdsourcing model does encourage participatory moderation.</p>
        
            <p>But professional fact-checking can be more effective at ensuring accuracy and consistency in content moderation, due to the expertise and rigourous methods of trained fact-checkers or automated models.</p>
        
            <p>However social media platforms, including Meta, make their revenue from user engagement.</p>
        
            <p>The type of content flagged as misleading or harmful often attracts more attention due to platform algorithms amplifying its reach.</p>
        
            <p>A 2022 US study for instance shows that political polarisation increases truth bias, which is the human tendency to believe people they identify with are telling the truth.</p>
        
            <p>This can lead to higher user engagement with disinformation, which is further amplified by algorithms that prioritise attention-grabbing content.</p>
        
            <p>
Social media platforms, including Meta, make their revenue from user engagement. 
Photo: 123RF
</p>
        
            <p>What might this mean for our digital information ecosystem?</p>
        
            <p>Without professional fact-checkers, the prevalence of false or misleading content will probably rise.</p>
        
            <p>Community-driven moderation may be inclusive and decentralised but it has its limitations.</p>
        
            <p>As shown by X's community notes, the success of crowdsourced moderation relies on both participation from informed users and users reaching a consensus on the notes, neither of which is guaranteed.</p>
        
            <p>Without independent fact-checking mechanisms, users may find it increasingly difficult to distinguish credible information from misinformation.</p>
        
            <p>As professional oversight diminishes, the responsibility for assessing content accuracy falls on users.</p>
        
            <p>But many social media users don't have the media literacy, time, or expertise needed to evaluate complex claims.</p>
        
            <p>This shift risks amplifying the spread of falsehoods, particularly among audiences who are less equipped to navigate the digital information landscape.</p>
        
            <p>Crowdsourced moderation is vulnerable to co-ordinated efforts by organised groups.</p>
        
            <p>A 2018 study examined millions of messages over several months to explore how social bots and user interactions contribute to the spread of information, particularly low-credibility content.</p>
        
            <p>The study found that social bots played a significant role in amplifying content from unreliable sources, especially during the early stages before an article went viral.</p>
        
            <p>This evidence shows that organised groups can exploit crowdsourced moderation to amplify the narratives that suit them.</p>
        
            <p>Such a dynamic could undermine the credibility and objectivity of the moderation process, eroding trust in the platform.</p>
        
            <p>Millions of X users have already migrated to its rival Bluesky for similar reasons.</p>
        
            <p>Unchecked misinformation can polarise communities, create distrust, and distort public debate.</p>
        
            <p>Governments, academics and social groups have already criticised social media platforms for their role in amplifying divisive content, and Meta's decision could intensify these concerns.</p>
        
            <p>The quality of discussions on Facebook and Instagram may decline as misinformation spreads more freely, potentially influencing public opinion and policy-making.</p>
        
            <p>There is no perfect solution to the challenges of content moderation.</p>
        
            <p>Meta's emphasis on free expression resonates with long-standing debates about the role of tech companies in policing online content.</p>
        
            <p>Critics of censorship argue that overly aggressive moderation suppresses important discussions.</p>
        
            <p>Meta aims to create a platform that fosters open dialogue and minimises the risk of suppression by reducing its reliance on fact-checkers.</p>
        
            <p>However the trade-offs are clear.</p>
        
            <p>Free expression without proper safeguards can enable the unchecked proliferation of harmful content including conspiracy theories, hate speech and medical misinformation.</p>
        
            <p>Achieving the right balance between protecting free speech and ensuring the integrity of information is a complex challenge and one that is evolving.</p>
        
            <p>Meta's announcement to shift from professional fact-checking to crowdsourced community moderation risks undermining this balance by amplifying the spread of disinformation and hateful speech.</p>
        
            <p>This story was originally published on The Conversation.</p>
        
        
        <div class="hr-line"></div>
        <br>
        <footer>
            <nav class="lower-nav-container">
              <li><a href="https://tom.so/experiment/txtrnz">About this site</a></li>
              <li><a href="https://www.rnz.co.nz/about">About RNZ</a></li>
            </nav>
          </footer>
    </body>
</html>