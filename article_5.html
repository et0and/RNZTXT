<!DOCTYPE html>
<html lang="en">
<html>
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="../static/styles.css">
        <title>TXTRNZ</title>
    </head>
    <body>
    <header>
        <p>Text-Only Version <a class="full-version-link button" href="https://www.rnz.co.nz/news/national/522236/government-checks-for-bias-in-facial-recognition-tech-as-fears-linger-over-racism">Go to article page</a></p>
    </header>
    <h1><a href="/">TXTRNZ</a></h1>
        <div class="hr-line"></div>
        <h2>Fears of racist facial recognition tech lingers</h2>
        <p>
Facial recognition is known for misidentifying people with darker skin, but that perception is outdated, experts say.
</p>
        
            <p>
Photo: 123rf
</p>
        
            <p>The public sector is checking for bias in its facial recognition technologies as fears persist that the tech is racist.</p>
        
            <p>Facial recognition first sparked controversy worldwide a decade ago after studies found it misidentified Black and brown faces much more than white ones, and especially for women.</p>
        
            <p>Some systems showed a racial or gender bias of four percent.</p>
        
            <p>Many algorithms were 10 to 100 times more likely to inaccurately identify a photo that was not of a white face, it was reported in 2019.</p>
        
            <p>The Department of Internal Affairs launched Identity Check a few months ago, without its possible racial bias being fully tested. However, a MƒÅori reference group said it was "comfortable" the technology would catch up.</p>
        
            <p>The DIA told RNZ on Friday that it now had a globally recognised laboratory checking Identity Check's biometrics for bias. It would return the results in a few months.</p>
        
            <p>"We want to know more about fairness," it said.</p>
        
            <p>"We are committed to the ethical and responsible use of [facial recognition]."</p>
        
            <p>The DIA uses Identity Check for photos that people submit for use in passports and in online identity verification. It and Customs have some of the busiest facial recognition systems in the country.</p>
        
            <p>The Ministry of Social Development also uses Identity Check to identify beneficiaries, if they choose to use that method. Their identities are verified online in real time.</p>
        
            <p>The system is a form of one-to-one photo matching, as opposed to the less accurate one-to-many matching.</p>
        
            <p>Last week, the DIA issued a tender, asking tech companies to tell it how it could improve its capture of deepfakes and other fraud.</p>
        
            <p>The tender asked companies to describe how their facial recognition systems performed around false acceptance, false rejection rates and bias.</p>
        
            <p>"Fraud and threats in our environment are ever-present," it said.</p>
        
            <p>"We need to keep adjusting our technologies to stay ahead of this."</p>
        
            <p>Meanwhile, universities in the United States have been training facial recognition systems on AI-generated facial images, with tests returning far more accurate results than previously.</p>
        
            <p>Some systems were now down to 0.02 percent inaccuracy, testing by the US National Institute of Standards and Technology showed.</p>
        
            <p>The perception that facial recognition technology was racist persisted, but it was "wrong", US thinktank Lawfare said.</p>
        
            <p>"For all the intense press and academic focus on the risk of bias in algorithmic face recognition, it turns out to be a tool that is very good and getting better."</p>
        
            <p>At New York University, researchers generated 13 million synthetic images of faces from six major racial groups - Black, Indian, Asian, Hispanic, Middle Eastern and white - to train three types of facial recognition.</p>
        
            <p>"The result not only boosted overall accuracy compared to models trained on existing imbalanced datasets, but also significantly reduced demographic bias," they reported in April.</p>
        
            <p>The researchers had open-sourced their code for others to use.</p>
        
            <p>Facial recognition bias expert Ifeoma Nwogu, from the University of Buffalo, said facial recognition technology "continues to get better with time, with improved camera technologies, more diverse datasets".</p>
        
        
        <div class="hr-line"></div>
        <br>
        <footer>
            <nav class="lower-nav-container">
              <li><a href="https://tom.so/experiment/txtrnz">About this site</a></li>
              <li><a href="https://www.rnz.co.nz/about">About RNZ</a></li>
            </nav>
          </footer>
    </body>
</html>