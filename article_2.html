<!DOCTYPE html>
<html lang="en">
<html>
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="../static/styles.css">
        <title>TXTRNZ</title>
    </head>
    <body>
    <header>
        <p>Text-Only Version <a class="full-version-link button" href="https://www.rnz.co.nz/news/national/512743/young-person-found-hoarding-thousands-of-child-exploitation-animal-cruelty-images">Go to article page</a></p>
    </header>
    <h1><a href="/">TXTRNZ</a></h1>
        <div class="hr-line"></div>
        <h2>Young person found hoarding thousands of child exploitation, animal cruelty images</h2>
        <p>
The person's family thought they were online gaming and had a "major shock" when they discovered the truth.
</p>
        
            <p>
File photo. 
Photo: Erwi / Unsplash
</p>
        
            <p>A young person whose family thought they were playing video games was actually hoarding thousands of images of child exploitation, violent extremism, gore and animal cruelty.</p>
        
            <p>The case was outlined in the Digital Violent Extremism Transparency report released on 26 March.</p>
        
            <p>It showed Internal Affairs investigators were tackling a rising tide of violent content.</p>
        
            <p>Investigators got 60 alerts about the young person. When they raided their home, it came as a "major shock" to their family, the report said.</p>
        
            <p>"The family of the individual had no prior concerns ... they thought the individual was merely online gaming, although their online time was unsupervised."</p>
        
            <p>The young person had quickly become engrossed by extremist content, reinforced by others online.</p>
        
            <p>The case was exposed by the National Centre of Missing and Exploited Children, which alerted Operation Flare, a DIA operation last year that looked into groups sharing objectionable content.</p>
        
            <p>Referrals about content were up by a quarter, the report showed, to almost 900 in 2023.</p>
        
            <p>About 40 percent of the content flagged was found to be objectionable.</p>
        
            <p>"The most commonly reported ideology type was 'Identity motivated', specifically 'white-identity'."</p>
        
            <p>The platforms X/Twitter, Telegram and TikTok got the most complaints - though TikTok removed over three-quarters of harmful content before DIA had to formally request it.</p>
        
            <p>Just over half the content referred had to do with the 15 March mosque attacks, including from a Russia-owned platform, where the department succeeded in part by working with Europol to get it removed.</p>
        
            <p>Informal and formal takedown requests got several hundred lots of content removed.</p>
        
        
        <div class="hr-line"></div>
        <br>
        <footer>
            <nav class="lower-nav-container">
              <li><a href="https://tom.so/experiment/txtrnz">About this site</a></li>
              <li><a href="https://www.rnz.co.nz/about">About RNZ</a></li>
            </nav>
          </footer>
    </body>
</html>